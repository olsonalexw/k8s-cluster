apiVersion: v1
kind: ConfigMap
metadata:
  name: qbittorrent-trim-script
data:
  trim_seeders.py: |
    from qbittorrentapi import Client
    import os
    import time
    import json
    print("Starting trim script")

    # Connect to qBittorrent
    username = os.getenv('QBT_USER')
    password = os.getenv('QBT_PASS')
    if username and password:
        client = Client(host='qbittorrent.media.svc.cluster.local', port=80, username=username, password=password)
    else:
        raise ValueError("QBT_USER and QBT_PASS env vars must be set")

    # Constants
    MIN_RATIO = 1.1
    MIN_SEEDING_HOURS = 337
    MAX_SEEDERS = 15
    IPT_TAG = 'iptorrents'
    DRY_RUN = False  # Set to False to actually delete

    # History file for tracking per-torrent snapshots
    history_file = '/downloads/seeder_history.json'
    try:
        with open(history_file, 'r') as f:
            history = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        history = {}

    current_ts = time.time()

    # Get all seeding torrents for IPT tag
    torrents = client.torrents_info(status_filter='seeding', tag=IPT_TAG)

    # Prepare data for each torrent
    torrent_data = []
    for t in torrents:
        h = t.hash
        current_up = t.uploaded
        current_st = t.seeding_time
        delta_up = current_up
        delta_st = current_st
        if h in history and history[h]:
            hist_list = sorted(history[h], key=lambda x: x['ts'])
            three_days_ago = current_ts - 3 * 86400
            for entry in hist_list:
                if entry['ts'] >= three_days_ago:
                    delta_up = current_up - entry['up']
                    delta_st = current_st - entry['st']
                    break
        prod_hours = max(delta_st / 3600.0, 1e-6)  # Avoid div0
        productivity = (delta_up / 1e9) / prod_hours
        seeding_hours = current_st / 3600.0
        is_eligible = t.ratio >= MIN_RATIO or seeding_hours >= MIN_SEEDING_HOURS
        torrent_data.append((productivity, is_eligible, h, t.name, seeding_hours, t.ratio, t.category))

    # Update history with current snapshots (after processing)
    new_history = {}
    for t in torrents:
        h = t.hash
        if h not in new_history:
            new_history[h] = []
        if h in history:
            new_history[h] = history[h][:]
        new_history[h].append({'ts': current_ts, 'up': t.uploaded, 'st': t.seeding_time})
        # Prune old entries (keep ~5 days for buffer)
        hist_list = sorted(new_history[h], key=lambda x: x['ts'])
        prune_ts = current_ts - 5 * 86400
        hist_list = [e for e in hist_list if e['ts'] >= prune_ts]
        new_history[h] = hist_list

    with open(history_file, 'w') as f:
        json.dump(new_history, f)

    total = len(torrent_data)
    print(f"Total seeding torrents with tag '{IPT_TAG}': {total}")
    print("\nProductivity report:")
    print("-" * 80)
    print(f"{'Name':<50} {'Prod (GB/h)':<12} {'Hours':<8} {'Ratio':<6} {'Eligible'}")
    print("-" * 80)
    # Sort by productivity descending for nicer print (highest first)
    sorted_for_print = sorted(torrent_data, key=lambda x: x[0], reverse=True)
    for prod, eligible, hash_val, name, hours, ratio, category in sorted_for_print:
        print(f"{name[:49]:<50} {prod:<12.4f} {hours:<8.1f} {ratio:<6.3f} {eligible}")

    if total <= MAX_SEEDERS:
        print(f"\nTotal at or below {MAX_SEEDERS}; no deletions needed.")
    else:
        excess = total - MAX_SEEDERS
        print(f"\nExcess torrents: {excess}. Identifying candidates for deletion...")

        # Sort by productivity ascending (least productive first)
        sorted_torrents = sorted(torrent_data, key=lambda x: x[0])

        # Candidates are the least productive 'excess' torrents
        candidates = sorted_torrents[:excess]
        to_delete = []
        for prod, eligible, hash_val, name, hours, ratio, category in candidates:
            if not eligible:
                print(f"  Skipping {name[:50]} (prod: {prod:.4f} GB/h) - not eligible (ratio: {ratio:.3f}, hours: {hours:.1f})")
            else:
                to_delete.append((hash_val, name, prod, category))

        num_to_delete = len(to_delete)
        if num_to_delete > 0:
            print(f"\nEligible for deletion: {num_to_delete}")
            print("-" * 60)
            print(f"{'Name':<50} {'Prod (GB/h)'}")
            print("-" * 60)
            for hash_val, name, prod, category in sorted(to_delete, key=lambda x: x[2]):  # sort by prod asc for display
                if DRY_RUN:
                    print(f"Would delete: {name[:49]:<50} {prod:<12.4f}")
                else:
                    delete_files = category != "manual"
                    action = "Deleting (with files)" if delete_files else "Deleting (keep files)"
                    print(f"{action}: {name[:49]:<50} {prod:<12.4f}")
                    client.torrents_delete(delete_local_files=delete_files, torrent_hashes=hash_val)
                    time.sleep(1)  # Avoid API flood
        else:
            print(f"\nNo eligible candidates among the {excess} least productive torrents; no deletions.")

        final_total = total - num_to_delete
        print(f"\nProcessed {total} torrents. Will have {final_total} seeding torrents remaining.")
